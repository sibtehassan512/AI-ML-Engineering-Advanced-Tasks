{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwmgSOE7t7RK",
        "outputId": "b9e6cc20-c0c3-4d40-9c9a-c4ec78e0ce32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries for data processing, modeling, and pipeline creation\n",
        "!pip install pandas numpy scikit-learn joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "# Download the Telco Customer Churn dataset from a public URL\n",
        "url = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
        "urllib.request.urlretrieve(url, \"Telco-Customer-Churn.csv\")\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv(\"Telco-Customer-Churn.csv\")\n",
        "\n",
        "# Clean up specific columns\n",
        "# Replace 'No internet service' and 'No phone service' with 'No' for consistency\n",
        "df = df.replace(['No internet service', 'No phone service'], 'No')\n",
        "\n",
        "# Convert TotalCharges to numeric, setting invalid values to NaN\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Display first few rows to verify\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHIqx0qouNYk",
        "outputId": "2c4131b5-5ebb-46b6-b2c3-a639e598f628"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
            "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
            "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
            "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
            "3  7795-CFOCW    Male              0      No         No      45           No   \n",
            "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
            "\n",
            "  MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
            "0            No             DSL             No  ...               No   \n",
            "1            No             DSL            Yes  ...              Yes   \n",
            "2            No             DSL            Yes  ...               No   \n",
            "3            No             DSL            Yes  ...              Yes   \n",
            "4            No     Fiber optic             No  ...               No   \n",
            "\n",
            "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
            "0          No          No              No  Month-to-month              Yes   \n",
            "1          No          No              No        One year               No   \n",
            "2          No          No              No  Month-to-month              Yes   \n",
            "3         Yes          No              No        One year               No   \n",
            "4          No          No              No  Month-to-month              Yes   \n",
            "\n",
            "               PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
            "0           Electronic check          29.85         29.85     No  \n",
            "1               Mailed check          56.95       1889.50     No  \n",
            "2               Mailed check          53.85        108.15    Yes  \n",
            "3  Bank transfer (automatic)          42.30       1840.75     No  \n",
            "4           Electronic check          70.70        151.65    Yes  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "# Drop customerID (irrelevant) and Churn (target)\n",
        "X = df.drop(['customerID', 'Churn'], axis=1)\n",
        "# Convert Churn to binary (1 = Churn, 0 = No Churn)\n",
        "y = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Split into training (80%) and test (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Print shapes to confirm split\n",
        "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsZqREi8ugz7",
        "outputId": "3f7401f2-929c-4960-c359-e4d5451a15ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (5634, 19), (5634,)\n",
            "Test set shape: (1409, 19), (1409,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "categorical_cols = [col for col in X.columns if col not in numerical_cols]\n",
        "\n",
        "# Numerical pipeline: impute missing values (median), then scale\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical pipeline: impute missing values (most frequent), then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Test preprocessor on a small sample\n",
        "print(\"Preprocessing columns:\")\n",
        "print(f\"Numerical: {numerical_cols}\")\n",
        "print(f\"Categorical: {categorical_cols}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXBDEvUzulAk",
        "outputId": "7d6e31bd-7782-4cac-b840-b0ea30835269"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing columns:\n",
            "Numerical: ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
            "Categorical: ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'logistic_regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'random_forest': RandomForestClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Define hyperparameter grids for GridSearchCV\n",
        "param_grid = {\n",
        "    'logistic_regression': {\n",
        "        'model__C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
        "        'model__penalty': ['l2']          # L2 regularization\n",
        "    },\n",
        "    'random_forest': {\n",
        "        'model__n_estimators': [100, 200],      # Number of trees\n",
        "        'model__max_depth': [10, 20, None],     # Max depth of trees\n",
        "        'model__min_samples_split': [2, 5]      # Min samples to split\n",
        "    }\n",
        "}\n",
        "\n",
        "# Print model and parameter info\n",
        "print(\"Models to train:\", list(models.keys()))\n",
        "print(\"Hyperparameters for tuning:\", param_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcHqCR_zupRQ",
        "outputId": "4cf07269-5a62-47d7-fe3b-b8bfd8755a3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models to train: ['logistic_regression', 'random_forest']\n",
            "Hyperparameters for tuning: {'logistic_regression': {'model__C': [0.01, 0.1, 1, 10], 'model__penalty': ['l2']}, 'random_forest': {'model__n_estimators': [100, 200], 'model__max_depth': [10, 20, None], 'model__min_samples_split': [2, 5]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for model_name, model in models.items():\n",
        "    # Create pipeline: preprocessing + model\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    # Set up GridSearchCV\n",
        "    grid_search = GridSearchCV(\n",
        "        pipeline,\n",
        "        param_grid[model_name],\n",
        "        cv=5,               # 5-fold cross-validation\n",
        "        scoring='f1',       # Optimize for F1-score (good for imbalanced data)\n",
        "        n_jobs=-1           # Use all CPU cores\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    results[model_name] = {\n",
        "        'best_params': grid_search.best_params_,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_score': f1,\n",
        "        'classification_report': classification_report(y_test, y_pred, target_names=['No Churn', 'Churn'])\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nResults for {model_name}:\")\n",
        "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"Classification Report:\\n{results[model_name]['classification_report']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfjGfro0us6P",
        "outputId": "5cf62b4e-85eb-4faa-c5f0-d01d50e51b4c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for logistic_regression:\n",
            "Best Parameters: {'model__C': 10, 'model__penalty': 'l2'}\n",
            "Accuracy: 0.8048\n",
            "F1-Score: 0.6032\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    No Churn       0.85      0.89      0.87      1035\n",
            "       Churn       0.66      0.56      0.60       374\n",
            "\n",
            "    accuracy                           0.80      1409\n",
            "   macro avg       0.75      0.73      0.74      1409\n",
            "weighted avg       0.80      0.80      0.80      1409\n",
            "\n",
            "\n",
            "Results for random_forest:\n",
            "Best Parameters: {'model__max_depth': 10, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
            "Accuracy: 0.7984\n",
            "F1-Score: 0.5786\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    No Churn       0.84      0.90      0.87      1035\n",
            "       Churn       0.65      0.52      0.58       374\n",
            "\n",
            "    accuracy                           0.80      1409\n",
            "   macro avg       0.74      0.71      0.72      1409\n",
            "weighted avg       0.79      0.80      0.79      1409\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "\n",
        "# Save each model's pipeline\n",
        "for model_name, model in models.items():\n",
        "    best_model = grid_search.best_estimator_  # From the last grid_search (update if needed)\n",
        "    joblib.dump(best_model, f'telco_churn_{model_name}_pipeline.joblib')\n",
        "    print(f\"Saved pipeline: telco_churn_{model_name}_pipeline.joblib\")\n",
        "\n",
        "# Save evaluation results to JSON\n",
        "with open('telco_churn_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "print(\"Results saved to: telco_churn_results.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxzdYPk2v_O5",
        "outputId": "1044a2c4-5e80-4b29-a7a0-5a872a6963f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pipeline: telco_churn_logistic_regression_pipeline.joblib\n",
            "Saved pipeline: telco_churn_random_forest_pipeline.joblib\n",
            "Results saved to: telco_churn_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Random Forest pipeline\n",
        "loaded_pipeline = joblib.load('telco_churn_random_forest_pipeline.joblib')\n",
        "\n",
        "# Test on a few samples from the test set\n",
        "sample_data = X_test.iloc[:5]\n",
        "predictions = loaded_pipeline.predict(sample_data)\n",
        "\n",
        "# Print predictions\n",
        "print(\"\\nSample predictions from loaded Random Forest pipeline:\")\n",
        "for idx, pred in enumerate(predictions):\n",
        "    print(f\"Sample {idx+1}: {'Churn' if pred == 1 else 'No Churn'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "armk7FInwHsu",
        "outputId": "1591b606-e5fa-4e2e-f812-a35ab4ecb922"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample predictions from loaded Random Forest pipeline:\n",
            "Sample 1: No Churn\n",
            "Sample 2: Churn\n",
            "Sample 3: No Churn\n",
            "Sample 4: No Churn\n",
            "Sample 5: No Churn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L6PCdBLPwexL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}